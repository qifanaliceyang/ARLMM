# -*- coding: utf-8 -*-
"""phenotype_covariance_analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ow23YCxvIx2DjNM-EOC1-bwt6pkc-Qow
"""

import pandas as pd
import numpy as np
from google.colab import drive
from scipy.optimize import minimize
import matplotlib.pyplot as plt

file_path = '/Users/aliceyang/autoregressive_mixed_models'

def calculate_bilateral_average(csv_file, phenotype_name, time_points):
    """
    Calculates bilateral average phenotype values for specified time points from a CSV file.

    Args:
        csv_file (str): Path to the CSV file.
        phenotype_name (str): The base name of the phenotype (e.g., 'hippo').
        time_points (list): List of time point suffixes (e.g., ['sc', '12mo', '24mo']).

    Returns:
        pandas.DataFrame: DataFrame with bilateral average phenotype values for each time point.
        Returns None if an error occurs.
    """
    try:
        df = pd.read_csv(csv_file)
        avg_data = {}
        for time_point in time_points:
            l_col = f'L{phenotype_name}_{time_point}'
            r_col = f'R{phenotype_name}_{time_point}'
            avg_col = time_point

            if l_col not in df.columns or r_col not in df.columns:
                raise KeyError(f"Columns '{l_col}' or '{r_col}' not found.")

            avg_data[avg_col] = (df[l_col] + df[r_col]) / 2

        return pd.DataFrame(avg_data)

    except FileNotFoundError:
        print(f"Error: File '{csv_file}' not found.")
        return None
    except KeyError as e:
        print(f"Error: {e}")
        return None
    except Exception as e:
        print(f"An unexpected error occurred: {e}")
        return None

def calculate_correlation(df):
    """
    Performs correlation and covariance calculations on a DataFrame.

    Args:
        df (pandas.DataFrame): DataFrame containing phenotype data.

    Returns:
        tuple: A tuple containing the covariance matrix and correlation matrix.
               Returns None, None if an error occurs.
    """
    try:
        covariance_matrix = df.cov()
        correlation_matrix = df.corr()

        return covariance_matrix, correlation_matrix

    except Exception as e:
        print(f"An unexpected error occurred: {e}")
        return None, None

def calculate_bilateral_average(csv_file, phenotype_name, time_points):
    """
    Calculates bilateral average phenotype values for specified time points from a CSV file.

    Args:
        csv_file (str): Path to the CSV file.
        phenotype_name (str): The base name of the phenotype (e.g., 'hippo').
        time_points (list): List of time point suffixes (e.g., ['sc', '12mo', '24mo']).

    Returns:
        pandas.DataFrame: DataFrame with bilateral average phenotype values for each time point.
        Returns None if an error occurs.
    """
    try:
        df = pd.read_csv(csv_file)
        avg_data = {}
        for time_point in time_points:
            l_col = f'L{phenotype_name}_{time_point}'
            r_col = f'R{phenotype_name}_{time_point}'
            avg_col = time_point

            if l_col not in df.columns or r_col not in df.columns:
                raise KeyError(f"Columns '{l_col}' or '{r_col}' not found.")

            avg_data[avg_col] = (df[l_col] + df[r_col]) / 2

        return pd.DataFrame(avg_data)

    except FileNotFoundError:
        print(f"Error: File '{csv_file}' not found.")
        return None
    except KeyError as e:
        print(f"Error: {e}")
        return None
    except Exception as e:
        print(f"An unexpected error occurred: {e}")
        return None

def calculate_correlation(df):
    """
    Performs correlation and covariance calculations on a DataFrame.

    Args:
        df (pandas.DataFrame): DataFrame containing phenotype data.

    Returns:
        tuple: A tuple containing the covariance matrix and correlation matrix.
               Returns None, None if an error occurs.
    """
    try:
        covariance_matrix = df.cov()
        correlation_matrix = df.corr()

        return covariance_matrix, correlation_matrix

    except Exception as e:
        print(f"An unexpected error occurred: {e}")
        return None, None

def analyze_all_subgroups(file_paths, phenotype_name, time_points):
    """
    Analyzes correlation and covariance for multiple subgroups.

    Args:
        file_paths (dict): A dictionary mapping subgroup names to CSV file paths.
        phenotype_name (str): The base name of the phenotype (e.g., 'hippo').
        time_points (list): List of time point suffixes (e.g., ['sc', '12mo', '24mo']).
    """
    results = {}
    for subgroup, file_path in file_paths.items():
        print(f"\nAnalyzing subgroup: {subgroup}")
        avg_df = calculate_bilateral_average(file_path, phenotype_name, time_points)

        if avg_df is not None:
            covariance, correlation = calculate_correlation(avg_df)
            if covariance is not None and correlation is not None:
                print("Covariance Matrix:")
                print(covariance)
                print("\nCorrelation Matrix:")
                print(correlation)
                results[subgroup] = {"covariance": covariance, "correlation": correlation}
            else:
                print(f"Correlation calculation failed for {subgroup}.")
        else:
            print(f"Average calculation failed for {subgroup}.")
    return results

# Example usage:
file_paths = {
    'sCN': file_path + '/hippo_sCN.csv',
    'sMCI': file_path + '/hippo_sMCI.csv',
    'converter': file_path + '/hippo_converter.csv',
    'sAD': file_path + '/hippo_sAD.csv',
}
phenotype_name = 'hippo'
time_points = ['sc', '12mo', '24mo']

results = analyze_all_subgroups(file_paths, phenotype_name, time_points)

print(results['sCN']['correlation'])

def calculate_ar_parameters(correlation_matrix, lag):
    """
    Calculates autoregressive parameters from a correlation matrix for a flexible lag.

    Args:
        correlation_matrix (pandas.DataFrame): The correlation matrix.
        lag (int): The autoregressive lag.

    Returns:
        numpy.ndarray: The estimated autoregressive parameters.
        Returns None if an error occurs.
    """
    try:
        corr_array = correlation_matrix.values
        num_time_points = corr_array.shape[0]

        def objective_function(params):
            """Calculates the difference between the model and observed correlations."""
            model_corr = np.zeros_like(corr_array)
            for i in range(num_time_points):
                for j in range(num_time_points):
                    if i == j:
                        model_corr[i, j] = 1.0
                    else:
                        if abs(i - j) <= lag:
                            temp_sum = 0
                            for k in range(min(i,j), max(i,j)):
                                temp_sum += params[abs(i-j)-1] * model_corr[min(i,j), k]

                            model_corr[min(i,j),max(i,j)] = temp_sum
                            model_corr[max(i,j),min(i,j)] = temp_sum
                        else:
                            model_corr[min(i,j),max(i,j)] = calculate_ar_correlation(params,abs(i-j))
                            model_corr[max(i,j),min(i,j)] = calculate_ar_correlation(params,abs(i-j))

            return np.mean(np.abs(corr_array - model_corr))

        def calculate_ar_correlation(params, distance):
            """Recursively calculates correlation based on AR parameters and distance."""
            if distance == 0:
                return 1.0
            elif distance <= len(params):
                temp_sum = 0
                for k in range(distance):
                    temp_sum += params[k] * calculate_ar_correlation(params, distance - 1- k)
                return temp_sum
            else:
                temp_sum = 0
                for k in range(len(params)):
                    temp_sum += params[k] * calculate_ar_correlation(params, distance - 1- k)
                return temp_sum

        initial_params = [0.8] * lag  # Initial guess for AR(lag)
        result = minimize(objective_function, initial_params, method='Powell')
        return result.x

    except Exception as e:
        print(f"Error estimating AR parameters: {e}")
        return None

def objective_function(params, margin=0.05):
    """Calculates a margin-like MAE between the model and observed correlations."""
    model_corr = np.zeros_like(corr_array)
    # ... (rest of the code to calculate model_corr) ...
    error = np.abs(corr_array - model_corr)
    loss = np.where(error <= margin, 0, error - margin)  # Only penalize errors outside the margin
    return np.mean(loss)

# Example usage:
ar_parameters = {}  # Dictionary to store AR parameters

for subgroup, file_path in file_paths.items():
    print(f"\nAnalyzing subgroup: {subgroup}")
    avg_df = calculate_bilateral_average(file_path, phenotype_name, time_points)

    if avg_df is not None:
        covariance, correlation = calculate_correlation(avg_df)
        if covariance is not None and correlation is not None:
            ar_params = calculate_ar_parameters(correlation, lag)
            if ar_params is not None:
                ar_parameters[subgroup] = ar_params.tolist()  # Save AR parameters as a list
                print(f"Estimated AR({lag}) parameters: {ar_params}")
            else:
                print(f"AR parameter estimation failed for {subgroup}.")
        else:
            print(f"Correlation calculation failed for {subgroup}.")
    else:
        print(f"Average calculation failed for {subgroup}.")

# Print the AR parameters dictionary
print("\nAR Parameters Dictionary:")
print(ar_parameters)

# AR parameters for each subgroup
ar_params = {
    'sCN': 0.9650,
    'sMCI': 0.9603,
    'converter': 0.9683,
    'sAD': 0.9726
}

# Time in months from 0 to 60 with steps of 6 months
time_months = np.arange(0, 61, 6)

# Generate linear decay curves
decay_curves_linear = {
    group: [1 - (t / 12) * (1 - ar) for t in time_months]
    for group, ar in ar_params.items()
}

# Update the label for 'converter' to 'cMCI' in the legend
legend_labels = {
    'sCN': 'sCN',
    'sMCI': 'sMCI',
    'converter': 'cMCI',
    'sAD': 'sAD'
}

# Plot
plt.figure(figsize=(10, 6))
for group, values in decay_curves_linear.items():
    plt.plot(time_months, values, label=legend_labels[group], marker='o', color=colors[group])

# Adjust x-axis ticks
plt.xticks(time_months)

# Update y-axis limits
plt.ylim(0.7, 1.00)

# Place legend in the upper right corner
plt.xlabel('Time (Months)')
plt.ylabel('Aytocorrelation')
plt.title('Autoregressive Model for Hippocampal Volume Decay over 60 Months Compared with Baseline')
plt.legend(loc='upper right')
plt.grid(True)
plt.show()

